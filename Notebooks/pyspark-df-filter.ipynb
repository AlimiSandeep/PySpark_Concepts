{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName('PySparkLearning').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrayStructureData = [\n",
    "                        ((\"James\",\"\",\"Smith\"),[\"Java\",\"Scala\",\"C++\"],\"OH\",\"M\"),\n",
    "                        ((\"Anna\",\"Rose\",\"\"),[\"Spark\",\"Java\",\"C++\"],\"NY\",\"F\"),\n",
    "                        ((\"Julia\",\"\",\"Williams\"),[\"CSharp\",\"VB\"],\"OH\",\"F\"),\n",
    "                        ((\"Maria\",\"Anne\",\"Jones\"),[\"CSharp\",\"VB\"],\"NY\",\"M\"),\n",
    "                        ((\"Jen\",\"Mary\",\"Brown\"),[\"CSharp\",\"VB\"],\"NY\",\"M\"),\n",
    "                        ((\"Mike\",\"Mary\",\"Williams\"),[\"Python\",\"VB\"],\"OH\",\"M\")\n",
    "                    ]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, ArrayType\n",
    "\n",
    "arrayStructureSchema = StructType([\n",
    "                                    StructField('name', StructType([\n",
    "                                                             StructField('firstname', StringType(), True),\n",
    "                                                             StructField('middlename', StringType(), True),\n",
    "                                                             StructField('lastname', StringType(), True)\n",
    "                                                          ])),\n",
    "                                    StructField('languages', ArrayType(StringType()), True),\n",
    "                                    StructField('state', StringType(), True),\n",
    "                                    StructField('gender', StringType(), True)\n",
    "                                 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(data= arrayStructureData, schema = arrayStructureSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: struct (nullable = true)\n",
      " |    |-- firstname: string (nullable = true)\n",
      " |    |-- middlename: string (nullable = true)\n",
      " |    |-- lastname: string (nullable = true)\n",
      " |-- languages: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      "\n",
      "+--------------------+------------------+-----+------+\n",
      "|                name|         languages|state|gender|\n",
      "+--------------------+------------------+-----+------+\n",
      "|    [James, , Smith]|[Java, Scala, C++]|   OH|     M|\n",
      "|      [Anna, Rose, ]|[Spark, Java, C++]|   NY|     F|\n",
      "| [Julia, , Williams]|      [CSharp, VB]|   OH|     F|\n",
      "|[Maria, Anne, Jones]|      [CSharp, VB]|   NY|     M|\n",
      "|  [Jen, Mary, Brown]|      [CSharp, VB]|   NY|     M|\n",
      "|[Mike, Mary, Will...|      [Python, VB]|   OH|     M|\n",
      "+--------------------+------------------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame \"filter()\" with Column Condition\n",
    "\n",
    "Use Column with the condition to filter the rows from DataFrame, using this you can express complex condition by referring column names using dfObject.colname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+-----+------+\n",
      "|                name|         languages|state|gender|\n",
      "+--------------------+------------------+-----+------+\n",
      "|    [James, , Smith]|[Java, Scala, C++]|   OH|     M|\n",
      "| [Julia, , Williams]|      [CSharp, VB]|   OH|     F|\n",
      "|[Mike, Mary, Will...|      [Python, VB]|   OH|     M|\n",
      "+--------------------+------------------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  Single condition\n",
    "df.filter(df.state == 'OH').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same example can also written as below. In order to use this first you need to import `from pyspark.sql.functions import col`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+-----+------+\n",
      "|                name|         languages|state|gender|\n",
      "+--------------------+------------------+-----+------+\n",
      "|      [Anna, Rose, ]|[Spark, Java, C++]|   NY|     F|\n",
      "|[Maria, Anne, Jones]|      [CSharp, VB]|   NY|     M|\n",
      "|  [Jen, Mary, Brown]|      [CSharp, VB]|   NY|     M|\n",
      "+--------------------+------------------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "df.where(col('state') == 'NY').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+-----+------+\n",
      "|                name|         languages|state|gender|\n",
      "+--------------------+------------------+-----+------+\n",
      "|    [James, , Smith]|[Java, Scala, C++]|   OH|     M|\n",
      "|[Mike, Mary, Will...|      [Python, VB]|   OH|     M|\n",
      "+--------------------+------------------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Multiple conditions\n",
    "\n",
    "df.filter((df.state == 'OH') & (df.gender == 'M')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering on Nested Struct columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+-----+------+\n",
      "|                name|   languages|state|gender|\n",
      "+--------------------+------------+-----+------+\n",
      "| [Julia, , Williams]|[CSharp, VB]|   OH|     F|\n",
      "|[Mike, Mary, Will...|[Python, VB]|   OH|     M|\n",
      "+--------------------+------------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.name.lastname == 'Williams').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame \"filter()\" with SQL Expression\n",
    "\n",
    "If you are coming from SQL background, you can use that knowledge in PySpark to filter DataFrame rows with SQL expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+-----+------+\n",
      "|                name|         languages|state|gender|\n",
      "+--------------------+------------------+-----+------+\n",
      "|    [James, , Smith]|[Java, Scala, C++]|   OH|     M|\n",
      "|[Maria, Anne, Jones]|      [CSharp, VB]|   NY|     M|\n",
      "|  [Jen, Mary, Brown]|      [CSharp, VB]|   NY|     M|\n",
      "|[Mike, Mary, Will...|      [Python, VB]|   OH|     M|\n",
      "+--------------------+------------------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(\"gender  == 'M'\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter on an Array column\n",
    "\n",
    "When you want to filter rows from DataFrame based on value present in an array collection column, you can use `array_contains()` from Pyspark SQL functions which checks if a value contains in an array- if present it returns true otherwise false.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------------+-----+------+\n",
      "|            name|         languages|state|gender|\n",
      "+----------------+------------------+-----+------+\n",
      "|[James, , Smith]|[Java, Scala, C++]|   OH|     M|\n",
      "|  [Anna, Rose, ]|[Spark, Java, C++]|   NY|     F|\n",
      "+----------------+------------------+-----+------+\n",
      "\n",
      "+----------------+------------------+-----+------+\n",
      "|            name|         languages|state|gender|\n",
      "+----------------+------------------+-----+------+\n",
      "|[James, , Smith]|[Java, Scala, C++]|   OH|     M|\n",
      "|  [Anna, Rose, ]|[Spark, Java, C++]|   NY|     F|\n",
      "+----------------+------------------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import array_contains\n",
    "\n",
    "df.filter(array_contains(df.languages, 'Java')).show()\n",
    "df.where(array_contains(df.languages, 'Java')).show()\n",
    "#  filter() or where() results same output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
