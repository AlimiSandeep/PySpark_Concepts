{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "\n",
    "spark = SparkSession.builder.appName('PySparkLearning').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDF = [(('James','','Smith'),'1991-04-01','M',3000),\n",
    "          (('Michael','Rose',''),'2000-05-19','M',4000),\n",
    "          (('Robert','','Williams'),'1978-09-05','M',4000),\n",
    "          (('Maria','Anne','Jones'),'1967-12-01','F',4000),\n",
    "          (('Jen','Mary','Brown'),'1980-02-17','F',-1)\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "            StructField('name', \n",
    "                            StructType([\n",
    "                                StructField('first_name', StringType()), \n",
    "                                StructField('middle_name', StringType()),\n",
    "                                StructField('last_name', StringType())\n",
    "                            ])),\n",
    "            StructField('date_of_birth', StringType()),\n",
    "            StructField('gender', StringType()),\n",
    "            StructField('salary', IntegerType())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+------+------+\n",
      "|                name|date_of_birth|gender|salary|\n",
      "+--------------------+-------------+------+------+\n",
      "|    [James, , Smith]|   1991-04-01|     M|  3000|\n",
      "|   [Michael, Rose, ]|   2000-05-19|     M|  4000|\n",
      "|[Robert, , Williams]|   1978-09-05|     M|  4000|\n",
      "|[Maria, Anne, Jones]|   1967-12-01|     F|  4000|\n",
      "|  [Jen, Mary, Brown]|   1980-02-17|     F|    -1|\n",
      "+--------------------+-------------+------+------+\n",
      "\n",
      "root\n",
      " |-- name: struct (nullable = true)\n",
      " |    |-- first_name: string (nullable = true)\n",
      " |    |-- middle_name: string (nullable = true)\n",
      " |    |-- last_name: string (nullable = true)\n",
      " |-- date_of_birth: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame(data = dataDF, schema = schema)\n",
    "df.show()\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PySpark withColumnRenamed – To rename single and multiple DataFrame columns\n",
    "\n",
    "`withColumnRenamed(existingName, newNam)` - Returns a new DataFrame with a column renamed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: struct (nullable = true)\n",
      " |    |-- first_name: string (nullable = true)\n",
      " |    |-- middle_name: string (nullable = true)\n",
      " |    |-- last_name: string (nullable = true)\n",
      " |-- dob: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Rename Single Column\n",
    "\n",
    "df1 = df.withColumnRenamed('date_of_birth','dob')\n",
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: struct (nullable = true)\n",
      " |    |-- first_name: string (nullable = true)\n",
      " |    |-- middle_name: string (nullable = true)\n",
      " |    |-- last_name: string (nullable = true)\n",
      " |-- birth_date: string (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  Rename Multiple Columns\n",
    "\n",
    "df2 = df.withColumnRenamed('date_of_birth', 'birth_date')\\\n",
    "        .withColumnRenamed('gender', 'sex')\n",
    "\n",
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To rename a nested column in Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using \"Select\" -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- fname: string (nullable = true)\n",
      " |-- mname: string (nullable = true)\n",
      " |-- lname: string (nullable = true)\n",
      " |-- date_of_birth: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "df3 = df.select(col(\"name.first_name\").alias(\"fname\"),\n",
    "                col(\"name.middle_name\").alias(\"mname\"),\n",
    "                col(\"name.last_name\").alias(\"lname\"),\n",
    "                col(\"date_of_birth\"),\n",
    "                col(\"gender\"),\n",
    "                col(\"salary\")\n",
    "               )\n",
    "\n",
    "df3.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using PySpark \"StructType\" – \n",
    "Changing a column name on nested data is not straight forward and we can do this by creating a new schema with new DataFrame columns using StructType and use it using cast function as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_schema = StructType([\n",
    "                            StructField('fname', StringType()),\n",
    "                            StructField('mname', StringType()),\n",
    "                            StructField('lname', StringType())\n",
    "                        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: struct (nullable = true)\n",
      " |    |-- fname: string (nullable = true)\n",
      " |    |-- mname: string (nullable = true)\n",
      " |    |-- lname: string (nullable = true)\n",
      " |-- date_of_birth: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4 = df.select(col(\"name\").cast(new_schema),\n",
    "                col(\"date_of_birth\"),\n",
    "                col(\"gender\"),\n",
    "                col(\"salary\")\n",
    "               )\n",
    "df4.printSchema() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using PySpark DataFrame \"withColumn\" -\n",
    "\n",
    "When you have nested columns on PySpark DataFrame and if you want to rename it, use `withColumn` on a data frame object to create a new column from an existing and we will need to drop the existing column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date_of_birth: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      " |-- fname: string (nullable = true)\n",
      " |-- mname: string (nullable = true)\n",
      " |-- lname: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df5 = df.withColumn(\"fname\",col(\"name.first_name\")) \\\n",
    "        .withColumn(\"mname\",col(\"name.middle_name\")) \\\n",
    "        .withColumn(\"lname\",col(\"name.last_name\")) \\\n",
    "        .drop(\"name\")\n",
    "\n",
    "df5.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using toDF() – To change all columns in a PySpark DataFrame\n",
    "\n",
    "When we have data in a flat structure (without nested) , use `toDF()` with a new schema to change all column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- newCol-1: struct (nullable = true)\n",
      " |    |-- first_name: string (nullable = true)\n",
      " |    |-- middle_name: string (nullable = true)\n",
      " |    |-- last_name: string (nullable = true)\n",
      " |-- newCol-2: string (nullable = true)\n",
      " |-- newCol-3: string (nullable = true)\n",
      " |-- newCol-4: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "newColumns = [\"newCol-1\",\"newCol-2\",\"newCol-3\",\"newCol-4\"]\n",
    "df.toDF(*newColumns).printSchema()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
