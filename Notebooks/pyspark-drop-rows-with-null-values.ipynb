{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.master(\"local[1]\").appName('PySparkLearning').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- zipcode: integer (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- population: integer (nullable = true)\n",
      "\n",
      "+---+-------+--------+-------------------+-----+----------+\n",
      "|id |zipcode|type    |city               |state|population|\n",
      "+---+-------+--------+-------------------+-----+----------+\n",
      "|1  |704    |STANDARD|null               |PR   |30100     |\n",
      "|2  |704    |null    |PASEO COSTA DEL SUR|PR   |null      |\n",
      "|3  |709    |null    |BDA SAN LUIS       |PR   |3700      |\n",
      "|4  |76166  |UNIQUE  |CINGULAR WIRELESS  |TX   |84000     |\n",
      "|5  |76177  |STANDARD|null               |TX   |null      |\n",
      "+---+-------+--------+-------------------+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filePath=\"../Resources/small_zipcode.csv\"\n",
    "df = spark.read.options(header='true', inferSchema='true') \\\n",
    "          .csv(filePath)\n",
    "\n",
    "df.printSchema()\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PySpark Drop Rows with NULL Values\n",
    "\n",
    "DataFrame/Dataset has a variable `na` which is an instance of class `DataFrameNaFunctions` hence, you should be using `na` variable on DataFrame to use drop(). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Drop Rows with NULL Values in Any Columns\n",
    "By default `drop(`) without arguments remove all rows that have null values on any column of DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+------+-----------------+-----+----------+\n",
      "| id|zipcode|  type|             city|state|population|\n",
      "+---+-------+------+-----------------+-----+----------+\n",
      "|  4|  76166|UNIQUE|CINGULAR WIRELESS|   TX|     84000|\n",
      "+---+-------+------+-----------------+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.drop().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This removes all rows with null values and returns the clean DataFrame with id=4 where it doesn’t have any NULL values.\n",
    "\n",
    "Alternatively you can also get same result with `na.drop(\"any\")`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+------+-----------------+-----+----------+\n",
      "| id|zipcode|  type|             city|state|population|\n",
      "+---+-------+------+-----------------+-----+----------+\n",
      "|  4|  76166|UNIQUE|CINGULAR WIRELESS|   TX|     84000|\n",
      "+---+-------+------+-----------------+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.drop(\"any\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop Rows with NULL Values on All Columns\n",
    "Below example drops all rows that has NULL values on all columns. Our DataFrame doesn’t have null values on all rows hence below examples returns all rows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+--------+-------------------+-----+----------+\n",
      "| id|zipcode|    type|               city|state|population|\n",
      "+---+-------+--------+-------------------+-----+----------+\n",
      "|  1|    704|STANDARD|               null|   PR|     30100|\n",
      "|  2|    704|    null|PASEO COSTA DEL SUR|   PR|      null|\n",
      "|  3|    709|    null|       BDA SAN LUIS|   PR|      3700|\n",
      "|  4|  76166|  UNIQUE|  CINGULAR WIRELESS|   TX|     84000|\n",
      "|  5|  76177|STANDARD|               null|   TX|      null|\n",
      "+---+-------+--------+-------------------+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.drop(\"all\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Rows with NULL Values on Selected Columns\n",
    "\n",
    "In order to remove Rows with NULL values on selected columns of PySpark DataFrame, use `drop(columns:Seq[String]) or drop(columns:Array[String])`. To these functions pass the names of the columns you wanted to check for NULL values to delete rows.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+--------+-----------------+-----+----------+\n",
      "|id |zipcode|type    |city             |state|population|\n",
      "+---+-------+--------+-----------------+-----+----------+\n",
      "|1  |704    |STANDARD|null             |PR   |30100     |\n",
      "|4  |76166  |UNIQUE  |CINGULAR WIRELESS|TX   |84000     |\n",
      "+---+-------+--------+-----------------+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.drop(subset=[\"population\",\"type\"]) \\\n",
    "   .show(truncate=False)\n",
    "\n",
    "# Removes rows that have NULL values on population and type columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using dropna() of DataFrame\n",
    "Below is a PySpark example of using `dropna()` function of DataFrame to drop rows with NULL values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+------+-----------------+-----+----------+\n",
      "|id |zipcode|type  |city             |state|population|\n",
      "+---+-------+------+-----------------+-----+----------+\n",
      "|4  |76166  |UNIQUE|CINGULAR WIRELESS|TX   |84000     |\n",
      "+---+-------+------+-----------------+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.dropna().show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
